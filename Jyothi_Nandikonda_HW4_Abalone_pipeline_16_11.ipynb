{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################################3333\n",
    "#  Assignment 4\n",
    "#  Dataset: Abalone\n",
    "#  Deadline: 16.11.2018, 13:15\n",
    "#  Author: Jyothi Nandikonda\n",
    "####################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use `GridSearchCV` to compare `Ridge()` and `KNeighborsRegressor()` in predicting rings of Abalone dataset. Add several values to one parameter in Ridge and one in KNeighborsRegressor. \n",
    "Add several values to one parameter in Ridge and one in KNeighborsRegressor. \n",
    "2. The `cv_results_` property of a trained `GridSearchCV()` object provides a lot of information about the evaluation process.\n",
    "Print all `mean_test_score`s, and the parameter combinations to which they correspond.\n",
    "3. Implement Extreme Learning Machine (next slide) and find the optimal combination of parameters in predicting rings of Abalone dataset.\n",
    "Report test mean absolute error (on a separate test set that you prepared in the beginning); compare to `RandomForestRegressor`.\n",
    "Mean absolute error is `np.abs(y_test - model.predict(X_test)).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use GridSearchCV to compare Ridge() and KNeighborsRegressor() in predicting rings of Abalone dataset. Add several values to one parameter in Ridge and one in KNeighborsRegressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'abalone.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating columns\n",
    "names = [ 'Sex', 'Length', 'Diameter', 'Height', 'Whole weight', 'Shucked weight', 'Viscera weight', 'Shell weight', 'Rings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dataset\n",
    "df =  pd.read_csv(filename ,names = names, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing alphabetical values with numerical values\n",
    "replace_list = {\"Sex\" : {\"M\": 0, \"F\" : 1, \"I\": 2}}\n",
    "df.replace(replace_list,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is the input features\n",
    "x = np.array(df.drop(['Rings'],1))\n",
    "#y is the target \n",
    "y = np.array(df['Rings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pipelines\n",
    "from sklearn.pipeline import make_pipeline,Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import neccesary libraries\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV with Ridge and KNR usig Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining pipeline\n",
    "pipe = Pipeline([('preprocessing', StandardScaler()), ('regressor', Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessing', StandardScaler(copy=True, with_mean=True, with_std=True)), ('regressor', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining parm grid : models and their corresponing parameters\n",
    "param_grid = [\n",
    "{'regressor': [Ridge()], 'preprocessing': [StandardScaler()],\n",
    "'regressor__alpha': [0.0001, 0.001, 0.01, 0.1, 10]},\n",
    "{'regressor': [KNeighborsRegressor()],\n",
    "'preprocessing': [None], 'regressor__n_neighbors': [1, 10, 15, 25, 50, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessing', StandardScaler(copy=True, with_mean=True, with_std=True)), ('regressor', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'regressor': [Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)], 'preprocessing': [StandardScaler(copy=True, with_mean=True, with_std=True)], 'regressor__alpha': [0.0001, 0.001, 0.01, 0.1, 10]}, {'regressor...  weights='uniform')], 'preprocessing': [None], 'regressor__n_neighbors': [1, 10, 15, 25, 50, 100]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Defining gidsearchCV class\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.The cv_results_ property of a trained GridSearchCV() object provides a lot of information about the evaluation process. Print all mean_test_scores, and the parameter combinations to which they correspond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5303368 , 0.53033687, 0.53033758, 0.53034391, 0.52770258,\n",
       "       0.22142787, 0.51862159, 0.52533106, 0.51546017, 0.47666406,\n",
       "       0.42395328])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing mean test score\n",
    "grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "  'regressor': Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "     normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "  'regressor__alpha': 0.0001},\n",
       " {'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "  'regressor': Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "     normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "  'regressor__alpha': 0.001},\n",
       " {'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "  'regressor': Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "     normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "  'regressor__alpha': 0.01},\n",
       " {'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "  'regressor': Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "     normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "  'regressor__alpha': 0.1},\n",
       " {'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
       "  'regressor': Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "     normalize=False, random_state=None, solver='auto', tol=0.001),\n",
       "  'regressor__alpha': 10},\n",
       " {'preprocessing': None,\n",
       "  'regressor': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=100, p=2,\n",
       "            weights='uniform'),\n",
       "  'regressor__n_neighbors': 1},\n",
       " {'preprocessing': None,\n",
       "  'regressor': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=100, p=2,\n",
       "            weights='uniform'),\n",
       "  'regressor__n_neighbors': 10},\n",
       " {'preprocessing': None,\n",
       "  'regressor': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=100, p=2,\n",
       "            weights='uniform'),\n",
       "  'regressor__n_neighbors': 15},\n",
       " {'preprocessing': None,\n",
       "  'regressor': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=100, p=2,\n",
       "            weights='uniform'),\n",
       "  'regressor__n_neighbors': 25},\n",
       " {'preprocessing': None,\n",
       "  'regressor': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=100, p=2,\n",
       "            weights='uniform'),\n",
       "  'regressor__n_neighbors': 50},\n",
       " {'preprocessing': None,\n",
       "  'regressor': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "            metric_params=None, n_jobs=1, n_neighbors=100, p=2,\n",
       "            weights='uniform'),\n",
       "  'regressor__n_neighbors': 100}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the parameter combinations to which the mean test score corresponds\n",
    "grid.cv_results_['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True), 'regressor': Ridge(alpha=0.1, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001), 'regressor__alpha': 0.1}\n",
      "\n",
      "Best cross-validation score: 0.53\n",
      "Test-set score: 0.52\n"
     ]
    }
   ],
   "source": [
    "#the best optimal combination of parameters\n",
    "print(\"Best params:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implement Extreme Learning Machine (next slide) and find the optimal combination of parameters in predicting rings of Abalone dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing neccesary subclasses\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.base import RegressorMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining non linear model class\n",
    "class NonLinearModel(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        X_new = np.tanh(X)\n",
    "        return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x is the input features\n",
    "x = np.array(df.drop(['Rings'],1))\n",
    "#y is the target \n",
    "y = np.array(df['Rings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y,test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining pipe --> use standard scalar, project n components using Gaussian projection, apply nonlinear transformation and finally regression\n",
    "pipe_extreme = Pipeline([('preprocessing', StandardScaler()), ('projection', GaussianRandomProjection()), ('nonlinear', NonLinearModel()), ('regressor', Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parm grid for above pipe\n",
    "param_grid = [    \n",
    "{'regressor': [Ridge()], 'preprocessing': [StandardScaler()],'projection' : [GaussianRandomProjection()],\n",
    "'regressor__alpha': [ 0.001, 0.01, 0.1, 10,100] , 'projection__n_components': [1,2,4,5,6]},\n",
    "{'regressor': [RandomForestRegressor()],'preprocessing': [None],'projection' : [GaussianRandomProjection()],\n",
    " 'regressor__max_depth': [2, 4, 6, 8, 10],'regressor__max_leaf_nodes': [2, 4, 6, 8, 10], 'projection__n_components': [1,2,4,5,6]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocessing', StandardScaler(copy=True, with_mean=True, with_std=True)), ('projection', GaussianRandomProjection(eps=0.1, n_components='auto', random_state=None)), ('nonlinear', NonLinearModel()), ('regressor', Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'regressor': [Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)], 'preprocessing': [StandardScaler(copy=True, with_mean=True, with_std=True)], 'projection': [GaussianRandomProjection(eps=0.1, n_components=6, ...8, 10], 'regressor__max_leaf_nodes': [2, 4, 6, 8, 10], 'projection__n_components': [1, 2, 4, 5, 6]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining grid with scoring as accuracy by default\n",
    "grid = GridSearchCV(pipe_extreme, param_grid , cv=5)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:\n",
      "{'preprocessing': StandardScaler(copy=True, with_mean=True, with_std=True), 'projection': GaussianRandomProjection(eps=0.1, n_components=6, random_state=None), 'projection__n_components': 6, 'regressor': Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001), 'regressor__alpha': 10}\n",
      "\n",
      "Best cross-validation score: 0.47\n",
      "Test-set score: 0.49\n"
     ]
    }
   ],
   "source": [
    "#finding optimal combination\n",
    "print(\"Best params:\\n{}\\n\".format(grid.best_params_))\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Report test mean absolute error (on a separate test set that you prepared in the beginning); compare to RandomForestRegressor. Mean absolute error is np.abs(y_test - model.predict(X_test)).mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining customised score for Ridge regression\n",
    "class MAEForRidge(BaseEstimator, RegressorMixin):\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.ridge_ = Ridge().fit(X_train, y_train)\n",
    "        return self\n",
    "    def predict(self, X_test):\n",
    "        return self.ridge_.predict(X_test)\n",
    "    def score(self, X_test, y_test):\n",
    "        y_estimated = self.predict(X_test)\n",
    "        mae_ridge = np.abs(y_test - y_estimated).mean()\n",
    "        return mae_ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining customised score for Random forest regression\n",
    "class MAEForRandomForest(BaseEstimator, RegressorMixin):\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.model_ = RandomForestRegressor().fit(X_train, y_train)\n",
    "        return self\n",
    "    def predict(self, X_test):\n",
    "        return self.model_.predict(X_test)\n",
    "    def score(self, X_test, y_test):\n",
    "        y_estimated = self.predict(X_test)\n",
    "        mae_forest = np.abs(y_test - y_estimated).mean()\n",
    "        return mae_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param grid for customised ridge class\n",
    "param_grid = [    \n",
    "{'regressor': [MAEForRidge()], 'preprocessing': [StandardScaler()]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline for ridge\n",
    "pipe_ridge = Pipeline([('preprocessing', StandardScaler()), ('regressor', MAEForRidge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set score: 1.58\n"
     ]
    }
   ],
   "source": [
    "#grid for ridge\n",
    "grid = GridSearchCV(pipe_ridge, param_grid = param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#param grid for Random forest\n",
    "param_grid = [    \n",
    "{'regressor': [MAEForRandomForest()], 'preprocessing': [None]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline\n",
    "pipe_forest = Pipeline([('preprocessing', None), ('regressor', MAEForRandomForest())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-set score: 1.60\n"
     ]
    }
   ],
   "source": [
    "#grid for random forest\n",
    "grid = GridSearchCV(pipe_forest, param_grid = param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Test-set score: {:.2f}\".format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
